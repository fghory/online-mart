# main.py
import asyncio
import logging
from contextlib import asynccontextmanager
from typing import Annotated

from aiokafka import AIOKafkaConsumer
from aiokafka.errors import (
    KafkaConnectionError,
    TopicAlreadyExistsError,
    NotControllerError,
    LeaderNotAvailableError,
)
from fastapi import FastAPI, Depends
from aiokafka.admin import AIOKafkaAdminClient, NewTopic
from sqlmodel import Session, select

from .db import create_db_and_tables, get_session
from .models import ProductCreate, Products

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS = "broker:19092"  # Kafka broker address
KAFKA_TOPIC = "inventory_items"           # Topic to consume from
GROUP_ID = "inventory"                    # Consumer group ID

# Initialize Kafka Admin Client
admin_client = AIOKafkaAdminClient(
    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS
)

# Initialize Kafka Consumer
consumer = AIOKafkaConsumer(
    KAFKA_TOPIC,
    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
    group_id=GROUP_ID,
    auto_offset_reset="earliest",
    enable_auto_commit=True
)

async def create_kafka_topic():
    """Function to create Kafka topic before starting the consumer."""
    retries = 0
    MAX_RETRIES = 5
    RETRY_INTERVAL = 10  # seconds

    try:
        await admin_client.start()
        while retries < MAX_RETRIES:
            try:
                topic_list = [
                    NewTopic(name=KAFKA_TOPIC, num_partitions=1, replication_factor=1)
                ]
                await admin_client.create_topics(
                    new_topics=topic_list,
                    validate_only=False
                )
                logger.info(f"Topic '{KAFKA_TOPIC}' created successfully.")
                break
            except TopicAlreadyExistsError:
                logger.info(f"Topic '{KAFKA_TOPIC}' already exists.")
                break
            except (NotControllerError, LeaderNotAvailableError, KafkaConnectionError) as e:
                retries += 1
                logger.warning(f"Transient error ({e}), retrying {retries}/{MAX_RETRIES}...")
                await asyncio.sleep(RETRY_INTERVAL)
            except Exception as e:
                logger.error(f"Unexpected error during topic creation: {e}")
                raise
        else:
            raise Exception(f"Failed to create Kafka topic '{KAFKA_TOPIC}' after {MAX_RETRIES} retries.")
    finally:
        await admin_client.close()

async def consume_messages():
    """Function to consume messages continuously."""
    try:
        await consumer.start()
        logger.info("Kafka consumer started and connected to the broker.")
        async for msg in consumer:
            message = msg.value.decode('utf-8')  # Adjust decoding as per your message format
            logger.info(f"Consumed message: Topic={msg.topic}, Partition={msg.partition}, Offset={msg.offset}, Key={msg.key}, Value={message}, Timestamp={msg.timestamp}")
            # Here you can add processing logic, e.g., save to database
    except Exception as e:
        logger.error(f"Error in consumer: {e}")
    finally:
        await consumer.stop()
        logger.info("Kafka consumer stopped.")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan event to manage application startup and shutdown.
    """
    # Initialize the database and create tables
    create_db_and_tables()
    logger.info("Database created and tables ensured.")

    # Create Kafka topic
    await create_kafka_topic()

    # Start Kafka consumer as a background task
    consumer_task = asyncio.create_task(consume_messages())
    logger.info("Kafka consumer task started.")

    try:
        yield
    finally:
        # Cancel the consumer task on shutdown
        consumer_task.cancel()
        try:
            await consumer_task
        except asyncio.CancelledError:
            logger.info("Kafka consumer task has been cancelled.")

# Initialize FastAPI with lifespan event
app = FastAPI(
    lifespan=lifespan,
    title="Fahad Mart API App",
    version="0.0.1",
    servers=[
        {
            "url": "http://127.0.0.1:8000",  # ADD NGROK URL Here Before Creating GPT Action
            "description": "Development Server"
        }
    ]
)

@app.get("/products/", response_model=list[Products])
def get_products(session: Annotated[Session, Depends(get_session)]):
    items = session.exec(select(Products)).all()
    return items

@app.post("/products/", response_model=Products)
def create_product(item: ProductCreate, session: Annotated[Session, Depends(get_session)]):
    product_db = Products.model_validate(item)
    session.add(product_db)
    session.commit()
    session.refresh(product_db)
    return product_db
